{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9304412,"sourceType":"datasetVersion","datasetId":5634115}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Multi-classification problems occur when we have a class with more than two classes**","metadata":{}},{"cell_type":"markdown","source":"NOTE: \n* In chapter 2, we dealt with the development of a classifier for a two-class problem. There the values of the class were provided for us in numerical form. \n* In this chapter:\n    - we shall deal with a problem where the class is more than 2 (this is called multi-class problem)\n    - Furthermore, the data provided for this problem is such that the class are provided in \"string\" form rather than numerical form required by most neural network framework.\n    - Based on the point above, we shall be using the Categorical Crossentropy as the loss function.\n        - **Categorical Crossentropy** measures the difference between the predicted probabilities and the true label of the class we should have predicted. With this loss function, the loss is always big if the predicted probabilites is different from what we should have predicted. Deep dip on this. \n        - **Together with this, we also introduced another activation function: the **softmax******.\n\n* For this problem, the output will be vectors containing the probabilities of each class. *However, the output in the dataset are in the form of strings, so they must first be converted into categorical variables*\n\n* This less will show, how to first treat string output by converting them into categorical variable and then follow by one-hot encoding of this new variable\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Problem statement:\n*We have data about the positions of dart throws by four individuals. Using the position coordinates of past throws by these competitors, we wish to build a classifier that can differentiates who throws the dart. This problem is a multi-class classification problem since each dart can only be thrown by one of 4 competitors. So classes/labels are mutually exclusive, and therefore we can build classifier that will have a final layer that will have as many neurons as the competitors, pass the output of this layer to the softmax activation function to achieve a total sum of probabilities of 1 over all competitors.*","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom keras.api.models import Sequential\nfrom keras.api.layers import Dense, InputLayer\nfrom keras.api.utils import to_categorical, set_random_seed\n\nfrom sklearn.model_selection import train_test_split\n\nset_random_seed(123)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T01:31:48.375679Z","iopub.execute_input":"2024-09-05T01:31:48.376095Z","iopub.status.idle":"2024-09-05T01:32:03.335512Z","shell.execute_reply.started":"2024-09-05T01:31:48.376054Z","shell.execute_reply":"2024-09-05T01:32:03.334392Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## **Data importation and assessment**\n","metadata":{}},{"cell_type":"code","source":"# Import the data\ndart = pd.read_csv(\"/kaggle/input/dart-throws/darts_throws_competitors.csv\")\n\n# Check for data info - which will tell you the datatype and count\nprint(dart.info())\n\n# Check for missing values\nprint(dart.isnull().sum())\n\n# Print out a few rows of data to check\nprint(dart.head(4))","metadata":{"execution":{"iopub.status.busy":"2024-09-05T01:32:19.333169Z","iopub.execute_input":"2024-09-05T01:32:19.333894Z","iopub.status.idle":"2024-09-05T01:32:19.409077Z","shell.execute_reply.started":"2024-09-05T01:32:19.333848Z","shell.execute_reply":"2024-09-05T01:32:19.407982Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 800 entries, 0 to 799\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   xCoord      800 non-null    float64\n 1   yCoord      800 non-null    float64\n 2   competitor  800 non-null    object \ndtypes: float64(2), object(1)\nmemory usage: 18.9+ KB\nNone\nxCoord        0\nyCoord        0\ncompetitor    0\ndtype: int64\n     xCoord    yCoord competitor\n0  0.196451 -0.520341      Steve\n1  0.476027 -0.306763      Susan\n2  0.003175 -0.980736    Michael\n3  0.294078  0.267566       Kate\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Data pre-processing**\n    - Using the pandas Categorical() function here to convert string object to categorical object","metadata":{}},{"cell_type":"code","source":"# As you can see from above, the competitor column is a string\n\n# Separate out the input and output data\ninput_dat = dart.drop([\"competitor\"], axis = 1).values\noutput = dart[\"competitor\"]\n\n# Convert output to categorical using pandas Categorical() function\noutput_cat = pd.Categorical(output)                  ## Converts ordinary string to categorical object\noutput_cat_numbers = output_cat.codes                ## This will encode the labels with number\n\n# One hot encoding the above categorical numbers\noutput_cat_encoded = to_categorical(output_cat_numbers) ## This converts a vector into matrix\n\n\nprint(output_cat[:8])\n# Now print the one-hot encoded labels\nprint('One-hot encoded competitors: \\n',output_cat_encoded[:8])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T01:32:33.575330Z","iopub.execute_input":"2024-09-05T01:32:33.576333Z","iopub.status.idle":"2024-09-05T01:32:33.589735Z","shell.execute_reply.started":"2024-09-05T01:32:33.576285Z","shell.execute_reply":"2024-09-05T01:32:33.588423Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['Steve', 'Susan', 'Michael', 'Kate', 'Steve', 'Kate', 'Kate', 'Steve']\nCategories (4, object): ['Kate', 'Michael', 'Steve', 'Susan']\nOne-hot encoded competitors: \n [[0. 0. 1. 0.]\n [0. 0. 0. 1.]\n [0. 1. 0. 0.]\n [1. 0. 0. 0.]\n [0. 0. 1. 0.]\n [1. 0. 0. 0.]\n [1. 0. 0. 0.]\n [0. 0. 1. 0.]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### This is an alternative approach for the conversion and encoding","metadata":{}},{"cell_type":"code","source":"## An alternative method to convert the string object to numerical variable is via factors\noutput_factorized = output.copy().factorize()[0]\n#print(output_factorized)\n\n# One hot encoding the above categorical numbers\noutput_factorized_encoded = to_categorical(output_factorized) ## This converts a vector into matrix\nprint(output_factorized_encoded[:8])","metadata":{"execution":{"iopub.status.busy":"2024-09-03T01:59:42.125756Z","iopub.execute_input":"2024-09-03T01:59:42.126285Z","iopub.status.idle":"2024-09-03T01:59:42.135306Z","shell.execute_reply.started":"2024-09-03T01:59:42.126238Z","shell.execute_reply":"2024-09-03T01:59:42.134169Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[[1. 0. 0. 0.]\n [0. 1. 0. 0.]\n [0. 0. 1. 0.]\n [0. 0. 0. 1.]\n [1. 0. 0. 0.]\n [0. 0. 0. 1.]\n [0. 0. 0. 1.]\n [1. 0. 0. 0.]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Split the data into training and testing components**","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(input_dat, output_cat_encoded,\n                                                   test_size=0.2, stratify=output_cat_encoded)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T01:32:48.720787Z","iopub.execute_input":"2024-09-05T01:32:48.721266Z","iopub.status.idle":"2024-09-05T01:32:48.738499Z","shell.execute_reply.started":"2024-09-05T01:32:48.721209Z","shell.execute_reply":"2024-09-05T01:32:48.737263Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## **Build the model architecture**\n    - We wish to build a model with 3 dense layers of 128, 64 and 32 neurons each.\n    - Take note that we employ the softmax activation function here.","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(InputLayer(shape = (2,)))\nmodel.add(Dense(128, activation = \"relu\"))\nmodel.add(Dense(64, activation = \"relu\"))\nmodel.add(Dense(32, activation = \"relu\"))\n\n# For the output layer below,we add a dense layer with as many neurons as competitors: 4\n# We are also using the \"softmax\" activation function\nmodel.add(Dense(4, activation = \"softmax\"))\n\nmodel.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T01:33:15.653208Z","iopub.execute_input":"2024-09-05T01:33:15.653662Z","iopub.status.idle":"2024-09-05T01:33:15.775867Z","shell.execute_reply.started":"2024-09-05T01:33:15.653624Z","shell.execute_reply":"2024-09-05T01:33:15.774778Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m384\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,852\u001b[0m (42.39 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,852</span> (42.39 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,852\u001b[0m (42.39 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,852</span> (42.39 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"Softmax:\n\n - The output of a  vector of numbers pass to the softmax function is always between 0 and 1, and the sum of the outputs is always 1. It has the following formula: \n    $$ softmax(x_i) = e^{x_i}/\\sum_j {e^{x_j}}$$\n\n    - Use case: Used for multi-class classification, where the output can be interpreted as the probabilities of different classes.\n    - Simply, softmax converts the raw class scores into a probability distribution, ensuring that the total sum of probabilities across all classes is 1.","metadata":{}},{"cell_type":"markdown","source":"## **Compliling the model**","metadata":{}},{"cell_type":"code","source":"# Compile your model using categorical_crossentropy loss\nmodel.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-09-05T01:33:24.504265Z","iopub.execute_input":"2024-09-05T01:33:24.504732Z","iopub.status.idle":"2024-09-05T01:33:24.520347Z","shell.execute_reply.started":"2024-09-05T01:33:24.504691Z","shell.execute_reply":"2024-09-05T01:33:24.519246Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## **Fit the model on training and testing data**","metadata":{}},{"cell_type":"code","source":"model_fit = model.fit(X_train, y_train, epochs = 200, verbose = False)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T01:33:27.987493Z","iopub.execute_input":"2024-09-05T01:33:27.988514Z","iopub.status.idle":"2024-09-05T01:33:39.029323Z","shell.execute_reply.started":"2024-09-05T01:33:27.988459Z","shell.execute_reply":"2024-09-05T01:33:39.028120Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(model_fit)\n#print(model_fit.history[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-04T01:10:01.490484Z","iopub.execute_input":"2024-09-04T01:10:01.490954Z","iopub.status.idle":"2024-09-04T01:10:01.497413Z","shell.execute_reply.started":"2024-09-04T01:10:01.490910Z","shell.execute_reply":"2024-09-04T01:10:01.496217Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"<keras.src.callbacks.history.History object at 0x7d42fd0b4df0>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Evaluate the model**","metadata":{}},{"cell_type":"code","source":"model_eval = model.evaluate(X_test, y_test)\nprint(model_eval[1])","metadata":{"execution":{"iopub.status.busy":"2024-09-05T01:36:46.723656Z","iopub.execute_input":"2024-09-05T01:36:46.725125Z","iopub.status.idle":"2024-09-05T01:36:46.956750Z","shell.execute_reply.started":"2024-09-05T01:36:46.725070Z","shell.execute_reply":"2024-09-05T01:36:46.955530Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7989 - loss: 0.6411  \n0.793749988079071\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**NOTE**: *When computing the accuracy above, our model takes the class with the highest probability as the prediction. To verify this, we shall unpack the predictions using the .predict() function.*","metadata":{}},{"cell_type":"markdown","source":"## **Softmax predictions**\n    - The predict function always returns numpy array","metadata":{}},{"cell_type":"code","source":"preds = model.predict(X_test)\nprint(preds[:5])                               ## Print only the first 5 predictions\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T01:36:57.450161Z","iopub.execute_input":"2024-09-05T01:36:57.450644Z","iopub.status.idle":"2024-09-05T01:36:57.583263Z","shell.execute_reply.started":"2024-09-05T01:36:57.450599Z","shell.execute_reply":"2024-09-05T01:36:57.582066Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n[[0.24896052 0.25753847 0.00905691 0.4844441 ]\n [0.18438223 0.4074901  0.00924431 0.3988834 ]\n [0.9539735  0.01862632 0.01015766 0.01724253]\n [0.62357306 0.01534733 0.02088005 0.34019953]\n [0.10753637 0.00475325 0.00857344 0.879137  ]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**NOTE**: \n> As you can observe above, the prediction we get directly from the last. This is because we used the softmax activation function. As a result, for every input of 2 coordinates provided to our model in the X_test data, there's an output vector of 4 numbers. Each of these numbers encodes the probability of a given dart being thrown by one of the 4 possible competitors. Premised on this, you must know that when computing accuracy with the .evaluate() method, our model takes the class with the highest probability as the prediction. \n\nWe can do similar thing via the np.argmax() as shown below.","metadata":{}},{"cell_type":"code","source":"# A function that outputs the maximum within the 4 outputs of the last sigmoid layer\n\n# A useful numpy command to use here is np.argmax() function that returns the position of max in an array\npostion_max_probab = [np.argmax(k) for k in preds]\nposition_max_encoded = [np.argmax(k) for k in y_test]\ndict_predict_truelabel = {\"Predictions\":postion_max_probab, \"True labels\":position_max_encoded}\ndf = pd.DataFrame(dict_predict_truelabel)\nprint(df.head(15))\n\n# for i,pred in enumerate(preds):\n#     print(\"{} | {}\".format(np.argmax(pred), np.argmax(y_test[i])))","metadata":{"execution":{"iopub.status.busy":"2024-09-05T02:15:18.929674Z","iopub.execute_input":"2024-09-05T02:15:18.930599Z","iopub.status.idle":"2024-09-05T02:15:18.945747Z","shell.execute_reply.started":"2024-09-05T02:15:18.930555Z","shell.execute_reply":"2024-09-05T02:15:18.944162Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"    Predictions  True labels\n0             3            2\n1             1            3\n2             0            0\n3             0            1\n4             3            3\n5             2            2\n6             1            1\n7             2            2\n8             3            3\n9             2            2\n10            1            1\n11            1            1\n12            3            3\n13            0            0\n14            3            3\n","output_type":"stream"}]}]}